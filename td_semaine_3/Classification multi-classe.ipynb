{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\xbf}{{\\bf x}}\n",
    "\\newcommand{\\ybf}{{\\bf y}}\n",
    "\\newcommand{\\wbf}{{\\bf w}}\n",
    "\\newcommand{\\Ibf}{\\mathbf{I}}\n",
    "\\newcommand{\\Xbf}{\\mathbf{X}}\n",
    "\\newcommand{\\Rbb}{\\mathbb{R}}\n",
    "\\newcommand{\\vec}[1]{\\left[\\begin{array}{c}#1\\end{array}\\right]}\n",
    "$\n",
    "\n",
    "# Classification multi-classe\n",
    "Matériel de cours rédigé par Pascal Germain, 2019\n",
    "************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "torch.__version__ # Ce notebook a été conçu avec la version '1.2.0' de pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L'ensemble de données «MNIST»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repertoire_mnist = '../data/mnist/' # Modifier le répertoire au besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charger_mnist(repertoire, etiquettes=None, max_par_etiquettes=None):\n",
    "    if etiquettes is None:\n",
    "         etiquettes = np.arange(10)\n",
    "    images_list = [None] * len(etiquettes)\n",
    "    labels_list = [None] * len(etiquettes)\n",
    "    for i, val in enumerate(etiquettes):\n",
    "        nom_fichier = repertoire + f'mnist_{val}.gz'\n",
    "        images_list[i] = np.genfromtxt(nom_fichier, max_rows=max_par_etiquettes, dtype=np.float32)\n",
    "        nb = images_list[i].shape[0]\n",
    "\n",
    "        labels_list[i] = i*np.ones(nb, dtype=np.int64)\n",
    "        print(val, ':', nb, 'images')\n",
    "        \n",
    "    x = np.vstack(images_list)\n",
    "    y = np.concatenate(labels_list)\n",
    "    print('Total :', len(y), 'images')\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = charger_mnist(repertoire_mnist, etiquettes=None, max_par_etiquettes=1000)\n",
    "data_x = data_x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('data_x:', data_x.shape)\n",
    "print('data_y:', data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.imshow(data_x, cmap=plt.cm.gray, aspect=.025)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple_index = 5002\n",
    "exemple = data_x[exemple_index,:]\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.imshow(exemple.reshape(28,-1), cmap=plt.cm.gray, aspect=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelques outils de la librairie `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie python `scikit-learn` (https://scikit-learn.org) contient une collection d'outils pour l'apprentissage automatique (machine learning), dont plusieurs algorithmes d'apprentissage «classiques» (régression logistique, SVM, forêts aléatoires, boosting, etc.) \n",
    "\n",
    "Dans ce TD et le suivant, nous utiliserons principalement ses fonctionnalités de base pour le traitement des données. Pour en apprendre davantage sur les fonctionnalités de `scikit-learn`, vous êtes invité à consulter le notebook optionnel nommé «`Extra - La librairie scikit-learn.ipynb`».\n",
    "\n",
    "Pour tout connaître de scikit-learn, consultez le guide de l'utilisateur: https://scikit-learn.org/stable/user_guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Séparation des données en un ensemble d'apprentissage et un ensemble de test\n",
    "\n",
    "Voir: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.5, random_state=42)\n",
    "print('train_x:', train_x.shape)\n",
    "print('test_x:', test_x.shape)\n",
    "print('train_y:', train_y.shape)\n",
    "print('test_y:', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Algorithme d'apprentissage (Exemple de la régression logistique)\n",
    "\n",
    "Voir: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 1:** Initialiser l'algorithme d'apprentissage (constructeur de la *classe*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteur = LogisticRegression(C=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 2:** Exécuter l'algorithme sur les données d'apprentissage (méthode `fit`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteur.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteur.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Étape 3:** Prédire sur des nouvelles données (méthode `predict`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteur.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predicteur.predict(test_x[0:100,:])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Évaluer la performance d'un algorithme d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = predicteur.predict(train_x)\n",
    "test_pred = predicteur.predict(test_x)\n",
    "print('Précision train:', accuracy_score(train_y, train_pred) )\n",
    "print('Précision test :', accuracy_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Regardons quelques erreurs de classifications*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echecs = np.nonzero(predicteur.predict(test_x[0:100,:]) != test_y[0:100])\n",
    "echecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(echecs[0]), figsize=(15, 4))\n",
    "for i, ax in zip(echecs[0], axes):\n",
    "    ax.imshow(test_x[i].reshape(28,28), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réseaux de neurones multi-classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage par «minibatch»\n",
    "\n",
    "**Notez bien:** L'apprentissage par «minibatch» n'est pas particulier aux réseaux multi-classe, mais nous en profitons pour expliquer comment l'utiliser dans *pytorch* au passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (torch.arange(1, 11, dtype=torch.float32) * torch.ones(3,10, dtype=torch.float32)).transpose(0,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = 10 * torch.arange(1, 11) \n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in data:\n",
    "    print(x, '<-->', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DataLoader(data, batch_size=3)\n",
    "for t in range(4):\n",
    "    print('******* EPOQUE', t)\n",
    "    for x, y in sampler:\n",
    "        print('---------------')\n",
    "        print(x, '<-->', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DataLoader(data, batch_size=3, shuffle=True)\n",
    "for t in range(4):\n",
    "    print('******* EPOQUE', t)\n",
    "    for x, y in sampler:\n",
    "        print('---------------')\n",
    "        print(x, '<-->', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Couche de sortie «Softmax»\n",
    "\n",
    "Étant donné un problème de classification à $C$ classes, la couche de sortie du réseau possédera $C$ neurones avec la fonction d'activation «Softmax»:\n",
    "\n",
    "$$\\text{Softmax}(a_{i}) = \\frac{\\exp(a_i)}{\\sum_{j=1}^C \\exp(a_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1) # Il faut spécifier la dimension selon laquelle appliquer la normalisation\n",
    "sm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par la défition de la fonction SoftMax, le vecteur de sortie du réseau forme une distribution de probabilité:\n",
    "$$\\sum_{j=1}^C \\text{Softmax}(a_{i}) = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.sum(sm(X), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = torch.randn(10, 3)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(sm(X), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Couche de sortie «LogSoftmax»\n",
    "\n",
    "Pour des raisons de stabilité numérique, *pyTorch* préfère travailler avec le logarithme de l'activation SoftMax:\n",
    "\n",
    "$$\\text{LogSoftmax}(a_{i}) = \\log\\left(\\frac{\\exp(a_i) }{ \\sum_j \\exp(a_j)} \\right)\n",
    "= a_i - \\log\\left(\\sum_j \\exp(a_j) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.LogSoftmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsm = nn.LogSoftmax(dim=0) # Il faut spécifier la dimension selon laquelle appliquer la normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsm(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(sm(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "                nn.Linear(28**2, 10),\n",
    "                nn.LogSoftmax(dim=1) # Normalise chaque ligne\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrait_train_x = torch.tensor(train_x[0:5,:], dtype=torch.float32)\n",
    "extrait_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(extrait_train_x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Softmax}(a_{i}) = \\exp\\Big(\\text{LogSoftmax}(a_{i})\\Big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(pred).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le réseau prédit la classe correspondant à la valeur de sortie maximale:\n",
    "\n",
    "$$\\text{argmax}_i \\bigg[\\text{Softmax}(a_{i})\\bigg] = \\text{argmax}_i \\bigg[\\text{LogSoftmax}(a_{i})\\bigg]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perte du néfatif log vraissemblance associée à une sortie softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour nous faciliter la tâche, la fonction de perte `NLLLoss` est conçue pour gérer une paire d'arguments. Pour une minibatch de taille $m$ et un problème à $C$ classes, le calcul de la perte se fait à partir de:\n",
    "1. La prédiction donnée par une activation `LogSoftmax` (de taille $m\\times C$) ;\n",
    "2. La sortie désirée sous la forme d'un vecteur de $m$ éléments, chacun de ces éléments étant un entier de $0$ à $C-1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.NLLLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perte = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.ones(5, dtype=torch.int64)\n",
    "perte(pred, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfin: Classifions MNIST avec un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le répertoire de ce TD contient un fichier `reseau_classif_generique.py`. Par ce fichier, nous vous fournissons le code *pytorch* qui vous aidera à effectuer l'apprentissage d'un modèle de réseau multi-classe.\n",
    "\n",
    "La fonction d'apprentissage `ReseauClassifGenerique` utilise la descente de gradient stochastique avec momentum et «mini-batch». De plus, elle permet d'effectuer le «early stopping». "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reseau_classif_generique import ReseauClassifGenerique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReseauClassifGenerique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_entrees = 784\n",
    "nb_sorties = 10\n",
    "nb_neurones_cachees = 100\n",
    "\n",
    "modele_plein = nn.Sequential(\n",
    "            nn.Linear(nb_entrees, nb_neurones_cachees),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nb_neurones_cachees, nb_sorties),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "reseau_mnist = ReseauClassifGenerique(modele_plein, eta=.1, alpha=.1, nb_epoques=100, patience=20)\n",
    "reseau_mnist.apprentissage(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = reseau_mnist.prediction(train_x)\n",
    "test_pred = reseau_mnist.prediction(test_x)\n",
    "print('Précision train:', accuracy_score(train_y, train_pred) )\n",
    "print('Précision test :', accuracy_score(test_y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "stop_iter = reseau_mnist.meilleure_epoque-1\n",
    "plt.plot(reseau_mnist.liste_erreur_train, label=\"Erreur d'entrainement\")\n",
    "plt.plot(reseau_mnist.liste_erreur_valid, label='Erreur de validation')\n",
    "plt.scatter(stop_iter, reseau_mnist.liste_erreur_valid[stop_iter], s=300, c='r', marker='*', label='Early stopping')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.plot(reseau_mnist.liste_objectif, '--k', label='Valeur perte')\n",
    "plt.scatter(stop_iter, reseau_mnist.liste_objectif[stop_iter], s=300, c='r', marker='*', label='Early stopping')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "\n",
    "## À vous de jouer!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Répétez l'apprentissage du réseau de neurones avec différentes architectures (modèle): variez le nombre de couches, ainsi que le nombre de neurones par couches. \n",
    "2. Pour une architecture fixe, variez les paramètres de descente de gradient (eta et alpha), et analysez l'influence sur l'erreur de prédiction et la minimisation de la fonction objectif. Que se passe-t-il si les valeurs de ces paramètres sont trop petites ou trop grandes?\n",
    "3. Ouvrez le fichier `reseau_classif_generique.py` dans un éditeur texte. Regardez le code pour comprendre son fonctionnement (en particulier l'optimisation par minibatch, le early stopping, et la méthode `prediction`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
